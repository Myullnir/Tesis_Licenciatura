Código para generar .e a partir de los .c. Importante para el Prosem.c

"gcc -Wall -O3 -o miprog.e miprog.c -lm"

Para correr el programa el código es: "./miprog.e"

---------------------------------------------------------------------------------------

19/11/2020

Hoy voy a intentar revisar entre todos mis archivos viejos para organizarme todo lo que voy
a necesitar para empezar a trabajar. Tengo que revisar los .c, los .h, ver cómo funciona
el make file, cómo funciona el Ejecutar.sh, el Instanciar.sh.


---------------------------------------------------------------------------------------

25/11/2020

Voy a empezar a programar algunas boludeces, así ya voy de a poco recuperando el tacto con
esto. Después debería armarme un diagrama del orden de cosas para programar, así como la
jerarquía en que voy a plantear las funciones. Quizás convenga redefinir los nombres de
los archivos tipo avanzar, general y esos.

-----------------------------------------------------------------------------------------

26/11/2020

Luego de batallar con arrancar, ya estamos empezando. Me armé un diagrama de trabajo y una
lista de las cosas que tengo que poner en el programa. El diagrama lo tengo en una hoja
escrito a mano. Podría pasarlo a un power Point, ya veré si vale la pena.
Modifiqué el struct base, el llamado Red, para que tenga los elementos básicos que va a
necesitar el modelo. Tiene número de agentes, de tópicos, matriz de superposición, matriz de
adyacencia, vectores de opinión y una serie de parámetros más.
La próxima arrancamos con los elementos en inicializar. La función de Visualizar queda.
Creo que voy a borrar CCP y la otra la voy a modificar para que me arme la red. Arranquemos
con una inicialización fija, después planteamos que el sistema vaya variando los valores
de la matriz de superposición.

-----------------------------------------------------------------------------------------

27/11/2020

Bien, ya modifiqué el archivo de inicializar. Saqué el CCP que colocaba condiciones de
contorno cerradas. Esas no las voy a necesitar, porque al final mi sistema es una red
finita con N nodos, no hay condiciones de contorno que cumplir. Luego, el GenerarR lo adapte
para que me inicialice los vectores de opiniones. Lo probé, parece funcionar perfecto. Por
lo menos asigna números con fracción a todas las coordenadas correctamente. Pareciera
respetar el intervalo de valores. Le cambié el nombre al GenerarR y lo llamé GenerarOpi.

También modifiqué el programa de Visualizar, para que al final reciba un número que indique
qué vector es el que planeo mirar. Las opciones son "Vectores de Opiniones", "Matriz de
Superposición" y "Matriz de Adyacencia".

Además separé el struct original de Red en dos structs. El struct Red que contiene la matriz
de Superposición, la matriz de Adyacencia y la lista de vectores de opinión. El segundo
struct es Parametros, que contiene todos los parámetros del modelo.

Lo siguiente es armar dos funciones que me inicialicen la matriz de Superposición y la de
Adyacencia. De paso, se me acaba de ocurrir. Debería probar el numerar vectores con la 
notación usual de fila y columna "[i,j]", trabajándolos como matrices, en vez de trabajarlos
como vectores de una sola fila y muchas columnas, donde hago cosas como "[i*N+j]" para
designar los casilleros del vector.
Cuestión, cuando tenga todas las funciones de inicialización las voy a empaquetar en una
sola función, para que quede todo más prolijo. O quizás vea de encerrarlo en una pestaña.

Corte a las 9:40, me pareció que no valía matarse ahora. La dificultad ahora es cómo
escribir una matriz simétrica, considerando que yo las tengo armadas como una tira y no
como una matriz. Estoy seguro que alguna vuelta sencilla tiene que haber. Una propuesta que
tengo para los elementos diagonales y no tener que meter muchos if es armar todos los
elementos con algún criterio, (Armar una matriz random en cada instanciación no suena como
una buena idea.) y DESPUÉS reemplazar todos los elementos de la diagonal por 1.

-----------------------------------------------------------------------------------------

28/11/2020

Armé las funciones que estuve mencionando antes. Ya tengo GenerarOpi que me arma la lista
de vectores de Opinión de todos los agentes. También está GenerarAng, que me crea la mitad
de la matriz de Superposición. La otra mitad la voy a construir una vez que tenga armada
una función que me simetrice matrices. Esa función la voy a meter dentro del conjunto de
funciones generales, podría servir en un futuro. La situación es la misma con GenerarAdy. Me
genera la mitad de la matriz de Adyacencia, la otra la voy a construir por simetría.

Estuve probando el Visualizar. Algo raro le está pasando, pero empecemos aclarando que me
visualiza perfecto las matrices de Adyacencia  y Superposición. Pero por alguna razón viene
tirando un error con la matriz de Opiniones. Creo que el error es puramente en la 
visualización, que no tiene nada que ver con lo que realmente hay en la matriz. Me percaté
de esto para empezar porque observaba que los elementos de la última fila de esta matriz
cuando formaba el sistema con seis agentes eran todos cero. Algo estadísticamente improbable.
Cuestión, que dependiendo de la cantidad de filas los elementos de las últimas filas se ven
peor o mejor. Noté que si cambiaba a muchas filas y columnas, de repente todo se emparejaba.
También descarté que el problema sea el casteo o el armado del Vector. El casteo no es porque
pasé el vector a Double, que es la salida del Random, y sigue funcionando mal. El armado del
vector no es porque probé ponerle enteros, y sigue dando el error de que al visualizarlo me
muestra algo que no tiene sentido, como ceros en las últimas filas o números absurdamente
largos e inexplicables. Y estos números largos eran siempre los mismos, no cambiaban en un solo
número. Algo raro pasa ahi y todavía no descubrí qué es lo que está pasando. Para comprobar que
el vector está bien rellenado podrías armar una sumatoria con sus números y ver que den algo
correcto.

Ahora voy a armar una carpeta en Github para cargar todo esto. Yo diría que mañana vayas
haciendo pruebas con lo de sumatorias para verificar que el vector se llena de manera correcta.
Luego, empezá a revisar la visualización para ver qué clase de error puede estar teniendo. Al
final del día igual no es vital, pero bueno. Visualizar las redes puede facilitar el encontrar
errores.

-------------------------------------------------------------------------------------------

30/11/2020

Encontré el error. Al final el problema efectivamente estaba en la visualización. La culpa era
mía, obviamente. Yo le calculé mal el movimiento a lo largo de las filas. En pocas palabras, el
sujeto estaba yendo a mirar en posiciones de memoria que no le pertenecían al vector. Eso hizo
que visualizara cosas raras. Porque eran espacios de memoria que estaban ocupados por cosas
raras. De paso, le agregué a la visualización que se muestren sólo dos decimales después de
la coma. Para que sea más sencillo de ver.

Lo pensé mejor, voy a escribir el código de simetrización dentro de las mismas funciones de 
Generar*. Queda para el futuro armar funciones que tomen punteros, me midan el tamaño de los
punteros y desde ahí me simetricen la matriz. Igual, el proceso de simetrización es una línea.
Genial, ya se me simetrizan ambas matrices.

Bueno, armé dos funciones en los archivos de avanzar. Pero todavía no puedo decir que funcionen
bien. Probé hacer las cuentas. En el caso de un nodo sin conexión a nada, dan bárbaro las
cuentas. En el caso de que se conecte con alguien, ya no da tan bien. Todavía no descubro
porqué.

También me ocurrió algo inentendible para mi. En el struct me surgió un error incomprensible.
Agregué el diferencial de tiempo al struct, y lo puse junto a los otros float, por una cuestión
de orden, para agrupar los mismos tipos de datos. Cuestión que por alguna razón que no
comprendo, la posición de este elemento en el struct jodía todo el programa. Pero al cambiarlo
de lugar y llevarlo al fondo del struct, todo se organizaba y funcionaba bárbaro. Cosa que no
tiene sentido, porque el struct llama a sus elementos por nombre, no por posición. El orden
no debería importar. No sé porqué, pero alto error raro.

-------------------------------------------------------------------------------------------

05/12/2020

Por lo que leí en internet, no hay una forma en C de poder leer el tamaño del array al cual 
apunta el puntero. Pero lo que podemos hacer es un truco, y esto implica un cambio en la
forma de programar de ahora para SIEMPRE. Lo que vamos a hacer es que de ahora en más, al 
principio de cada vector los primeros dos números van a estar reservados para el tamaño
de la matriz. (Si es un vector, igual lo consideraré como matriz). De esta manera, siempre
podré tener acceso al tamaño de un array. Esto va a ser un cambio que voy a implementar mañana.

Ahora me voy a poner a jugar con los structs y cosas en Prosem.c. Quiero ver si puedo armar
funciones a las que les llegan punteros y de esa manera en vez de tener que pasar todo el struct,
le paso sólo el puntero correcto. ¿Porqué querrías volver a trabajar sólo con punteros, en vez de
usar el struct que es mejor? El tema es que los nombres de los elementos de los structs va
variando con cada trabajo, entonces una función como la de simetrizar matrices no puede trabajar
con recibir el struct, porque lo que yo voy a querer es que funcione para cada matriz que 
le paso independiente del nombre, pero al usar el struct tengo que especificar el nombre
del objeto, y eso me obligaría a crear una matriz de Simetrización para cada nuevo trabajo.

Veamos si podemos hacer algo con esto. Ok, probando en Prosem, cambiar el orden de los atributos
del struct Parametros no parece crear problemas. Lo cual es lo razonable, porque no los llamé
por ningún orden, los llamé por nombre. El motivo del error en la función main original 
sigue sin ser descubierto, mucho menos solucionado.

Ahora probemos a partir de una matriz inicial el pasarle a una función de visualización básica
el que me visualice mi matriz a partir de un puntero. Armé una visualización tranca haciendo
uso de esa idea de poner el tamaño de la matriz al principio. Está bueno el truco este.
Alguien mencionó también dejar un número para identificar el tipo de dato. Esa para el
futuro queda. No quiero sumar números al pedo, para no volverme loco en la definición
de valores y cosas.

Armé la función de visualización. Efectivamente, si defino el input como un puntero, y le
paso el puntero del struct entonces lo trabaja perfectamente. En este caso le pasé el
puntero red.Ady, es decir el que apunta a la matriz de Adyacencia de mi sistema, y me
lo graficó correctamente.

------------------------------------------------------------------------------------------

06/12/2020

Hoy lo que voy a hacer es un reformateo a todo incorporando nuevas prácticas de programación.
Estas consisten en:

.) Agregar una letra al nombre de una variable que defina el tipo de variable que es.
Esto lo separo del nombre de la función con un guión bajo. Los espacios en los
nombres los voy a separar con guiones bajos también. Es importante recordar
entonces que las primeras letras SIEMPRE indican el tipo de variable.

.) Voy a dejar espacios libres entre secciones de código, separando la parte de
inicializar, desarrollo, registro de datos y demás. También vamos a poner títulos.

.) En las primeras dos coordenadas de cada vector voy a colocar el tamaño del vector.
Siendo la primer coordenada las Filas y la segunda las Columnas.

Si sobra tiempo, armaré una función que haga un RK4. Aunque primero necesito una que
calcule correctamente el campo que define mi ecuación diferencial. Y estas funciones
necesitan ser probadas primero en Prosem para poder hacer las cuentas a mano y ver
que efectivamente hacen lo esperado.

##### Ya reformatee general.c y general.h ##########

##### Ya reformatee inicializar.c e inicializar.h ##########

Llegué al punto donde la función hace lo que ya hacía antes de empezar a formattear todo.
Mañana seguiré con esto. La idea es entonces primero armar la función de la ecuación
dinámica. Probarla que calcule correctamente. Hecho esto, pasamos a armar un RK4.
Es decir, mañana arrancamos laburando con el Prosem. Hecho esto, ya vamos a poder
poner el programa a evolucionar. Lo que va a quedar es registrar los datos y pasarlos
a Python.

Vamos a terminar el día de hoy subiendo todo lo correspondiente a Github. Vale
aclarar, los archivos avanzar los dejé afuera de la carpeta src, porque sino
al compilar el make all me los intenta levantar, y a esos todavía no los corregí.
Más que nada porque las funciones de la dinámica no están terminadas.

-----------------------------------------------------------------------------------------

07/12/2020

Corregí los nombres una vez más, porque ahora a los punteros les agregué la letra p.

Además, ya armé la función Din1 y la probé en el archivo Prosem. Ya lo testee y funciona,
tanto en el caso en que el sujeto no conecta con nadie como en el caso en que conecta con
alguien, la cuenta que hace es correcta. Estaría bueno conseguir un programa que me permita
hacer las cuentas con mayor facilidad, porque la verdad es una paja hacerlo en Geogebra.
Creo que voy a hacer las cuentas en Octave de ahora en más. Va a ser mejor, me puede hacer
los productos de matrices y eso va a ser mucho más rápido.

Voy a subir todo a Github ahora.

------------------------------------------------------------------------------------------

08/12/2020

Ya armé las funciones Din1 y Din2. Confío en que funcionan perfecto porque revisé las
cuentas yo mismo usando Octave. También, como para dejar constancia del test realizado
es que guardé una imagen que se llama Cáculos Din2. Es una imagen que tiene los
resultados obtenidos por el programa en C y las cuentas hechas con el Octave, donde
se puede ver que las pendientes calculadas en Octave coinciden totalmente con las 
calculadas en C. Para mayor claridad paso a describir qué son las matrices definidas
en Octave:

- Opi es la matriz de vectores de opinión transpuesto. El motivo de hacerlo transpuesto
es porque de esta manera el producto con la matriz Ang me daría en cada elemento la
suma de las opiniones de un agente en cada tópico ponderada por la superposición con
el tópico en cuestión. El hecho de usar la matriz de forma diferente a como lo hago en
C no implica ningún error de cuentas. No hay que olvidar que en C yo no tengo Matrices,
solamente tengo vectores muy largos. Por tanto el producto entre matrices y vectores
siempre lo termino armando yo. Y eso ya lo había revisado de que estaba bien.

- Ang es la matriz de superposición de tópicos. Por simplicidad, tiene unos en la
diagonal y 0.5 afuera.

- Sup es el producto de las matrices Ang y Opi. Como dije, contiene en cada elemento
la sumatoria de las opiniones de un cierto agente ponderadas según la superposición
de cada opinión con el tópico en consideración.

- Pendiente es el nómbre del resultado total del miembro de la derecha de la
ecuación diferencial.

- K es el parámetro homónimo de la ecuación diferencial. Representa la influencia social.

- alfa es el parámetro homónimo de la ecuación diferencial. Representa la
controversialidad de un tópico.

Ahora el chiste va a ser implementar el RK4. Estuve pensando en que el RK4 debería
tomar aparte de los structs, el puntero sobre el cual va a trabajar, el puntero
a la función que define el campo de mi problema, (En este caso sería Din2),
y algo interesante sería que tuviera un puntero propio dentro de la función.
Ese puntero debería guardar información sobre el estado inicial del puntero 
con el que voy a trabajar. Esa información va a ser necesaria durante el trabajo
RK4, pero terminada la función, se lo puede liberar y listo.

----------------------------------------------------------------------------------------

14/12/2020

Vamos a armar una función que realice el proceso de RK4. Mi idea es escribir una
función que sea bastante general. Para eso voy a tomar como referencia una versión
que encontré por internet. Todavía no tengo bien claras las ideas de cómo voy a
hacer funcionar la versión del RK4. Mi idea es que tome los structs y le pase
eso a la función. Por eso es que voy a estar dentro del RK4 trabajando la Matriz
de Opinión, definiéndola y redefiniéndola muchas veces.
Estaba con la duda de cómo guardar o manejar los datos correctamente, pero al
final llegué a la conclusión de que lo mejor sería tener vectores, definidos
por punteros como siempre, que me guarden los valores de las pendientes que
calculo para cada una de mis variables. Luego al final, luego de haber calculado
cada una de las pendientes, entonces sí uso todas las pendientes para calcular
el siguiente paso temporal del sistema.
Lo interesante para esto es que me di cuenta que iba a tener que hacer cada
cálculo de pendientes en orden, entonces tenía que escribir las 4 sumatorias.
Pero para simplificar la escritura de todas las sumatorias, se me ocurrió
usar un array de punteros. Por eso decidí probar el cómo usarlo en Prosem.
Ahí lo hice funcionar para que me genere la visualización de mi red.
Funciona bárbaro. Tengo que recordar no borrar eso. Voy a tener que
armar un protocolo de guardado de estas cosas. Mañana o en la semana,
lo próximo a hacer es ya implementar esto. Con esto ya básicamente tendría
armada la función del RK4. La paja va a ser comprobar que las cuentas están
bien hechas. Voy a estar un rato con el Octave mirando eso de seguro.

------------------------------------------------------------------------------------------

18/12/2020

Hoy avancé con la construcción de la función RK4. Hay varias cosas para 
discutir al respecto. Pero en términos de lo que quiero que haga, ya la
armé. Todavía no la probé ni revisé errores de tipeo, así que todavía
queda mucho hasta que esté lista. Además, todadvía estoy indeciso sobre
el formato de la función. Debería analizarlo un poco más, como para estar
seguro de que la función es perfectamente generalizable. Cosa que sería
de mucha utilidad.

Por otra parte, rearmé la función de visualizar, de manera de que sólo
tome un puntero de entrada y de eso haga la visualización. Para eso,
hice tres funciones, una que toma enteros, otra que toma floats y una
que toma doubles. Mi idea sería armar una función visualizar Global
que las encierre, que reciba un char que elija la función correcta 
y de ahí visualice. Aunque ahora que lo pienso, eso seguiría
teniendo el mismo problema de que no puedo pasar el vector que 
quiero a la función. ¿Habrá una forma de solucionar esto en el
futuro?

Cree una segunda función que es Duplicar, esa función me calcula
las pendientes de una ecuación diferencial que definí para probar
el RK4. La ecuación diferencial sería x' = 2x.

Volviendo al RK4, estoy empezando a usar más los arrays. También
introduje un array de chars, que eso también es nuevo para mi.
Hay muchas cosas, como los arrays, el meter un for para el free,
o el visualizar que podrían funcionar mal. Va a ver que mirar
todo eso la próxima vez. La próxima entonces hay que hacer
las cuentas y ver que el RK4 esté calculando bien.
Y después, repensar un poco la forma de que sea lo más general
posible. Quizás hacer unos gráficos escritos.

Pregunta importante, ¿Cómo guardar las distintas versiones de
cosas probadas en el Prosem? Podríamos hacer un archivo
llamado Archivo.c. Ahí voy guardando las cosas con descripción.
Así no me van ocupando espacio innecesario en mi archivo Prosem.
Me parece una idea genial.

------------------------------------------------------------------------------------------

21/12/2020

Estuve haciendo las pruebas del RK4 para hacerlo funcionar.
Increíblemente, pero en cuanto puse la función funco bastante
fácil, no tuvo tantos errores como esperaba.

Cuestión, hice las pruebas con ecuaciones diferenciales lineales
en las cuales la variación de mi variable estaba sujeta a
un múltiplo de su valor actual. Es decir, usé las ecuaciones
x'=2x y x'=5x. En la primera anoté los k manualmente y
comprobé que los cálculos estuvieran dando bien los k y
el valor final del sistema. Además, como conozco la solución
a estas ecuaciones puedo comprobar que tan lejos está lo
calculado con respecto a lo real. Elegí los valores de
dt y la constante que definen mi ecuación diferencial
de manera que evolucionar temporalmente un paso a mi sistema
sea equivalente a tomar los datos iniciales y multiplicarlos
por e en ambas ecuaciones.

Guardé una imagen que se llama cálculos RK4 en la cual se
puede ver a la derecha los resultados obtenidos por el 
programa RK4. Luego a la izquierda uso el Octave para
manualmente hacer los cálculos que el programa RK4 debería
estar haciendo. En este caso estoy evaluando el sistema
en el cual la ecuación diferencial es x'=5x. A continuación
está el paso a paso de las cuentas que hice:

.) Calculo k1 como los valores del sistema en tiempo t
multiplicados por 5.
.) Calculo k2 como los valores del sistema en tiempo t
sumados a k1 por dt/2 y todo eso multiplicado por 5
.) Calculo k3 como los valores del sistema en tiempo t
sumados a k2 por dt/2 y todo eso multiplicado por 5
.) Calculo k4 como los valores del sistema en tiempo t
sumados a k3 por dt y todo eso multiplicado por 5
.) Calculo el final como los valores del sistema en
tiempo t más el producto de dt sobre 6 con 
k1 más dos k2 más dos k3 más k4.
.) Corroboro el resultado de tomar los valores del
sistema a tiempo t y multiplicarlos por e.

Finalmente cabe notar que hay una diferencia en la 
segunda cifra decimal, lo cual marcaría que debería tomar
un avance temporal más chico del que tomé. Pero en conclusión,
el programa funciona perfecto. Me encanta. Sólo queda
pensar si se la puede hacer un poco más genérica y listo.

Ahora voy a incorporar esto al programa principal. Todavía no
terminé esto. Mañana lo primero que tengo que hacer es corregir
los struct que aparecen en todo el código y reemplazarlos
por los s_cosas. Con el tiempo se me ocurrirán formas de
hacer que eso funcione más fácil

----------------------------------------------------------------------------------

22/12/2020

Ya implementé el RK4 en el programa, funca bárbaro. Hice
las anotaciones sobre el bloque que creo es crucial para
la generalización de esta función en futuros trabajos.

Hice pruebas, el programa funciona muy bien, no tira
errores ni nada. Por ahora lo único que probé a variar
son los valores de K y los de la matriz de Superposición.
Los resultados son los siguientes:

.) Si los valores de la matriz de Superposición son todos
positivos, entonces todos los signos de los tópicos se
alinean.
.) Si los signos de los valores de la matriz de Superposición
se alternan, entonces lo que me ocurre es que los signos
de las columnas se alternan igualmente.
.) Si reduzco el valor de K a cero, el sistema tiende a cero.
.) Si aumento el valor de K el sistema al evolucionar
simplemente tiende a crecer.
.) Con un valor de Tiempo de integración = 20, el sistema
con K=0 logra llegar a un estado donde todos los agentes
tienen opinión nula en todos los tópicos.

Ahora lo que voy a hacer es cortar acá, mostrarle esto
a Pablo mañana y de ahí decidir qué vamos a hacer.
Si yo estuviera por mi cuenta y tuviera que decidir,
¿Cuál sería mi siguiente paso?

Razonablemente, yo diría que por ahora lo que tengo
entonces son sólo dos fotos, la inicial y la final
y que este fue un análisis muy cualitativo. Para
poder empezar a hacer un análisis más cuantitativo
voy a necesitar ver lo que ocurre durante el proceso.

Por tanto los siguientes objetivos serían:
1) Implementar una forma de tomar registro de
los datos para poder guardar mis vectores de
opinión.
2) Armar un programa para cargar estos datos a
Python.
3) Hacer un análisis de los datos. Para esto hay
que pensar de qué forma deberían graficarse los datos.
Se me ocurre que el caso de K=0 se pueden graficar
curvas de variación del valor promedio de la opinión
en cada tópico y ver cómo eso cae a cero.
4) Podría graficar el caso de K != 0 considerando la
direccionalidad de los vectores. Sería una forma
cualitativa pero un poco mejor que lo que tengo
ahora de visualizar la evolución del sistema. Me armo
una especie de Histograma donde voy contando cuántas
personas apuntan en cierta dirección, y las
direcciones las defino en base al signo del tópico.
Eso me ayudaría a ver cómo se van moviendo las personas
de una opinión a otra y si la condición inicial del
sistema afecta mucho al resultado final.
5) Otra opción viable es armar un scatter de puntos
de colores, donde cada color representa una opinión
y luego ir acercando los colores cuyas opiniones son
más similares.

-------------------------------------------------------------------------------------

23/12/2020

Hoy tuvimos la reunión con Pablo. Le mostré los resultados
obtenidos. Me aconsejó lo siguiente:

1) Guardar todos los gráficos que vaya realizando en un
powerpoint. De esta manera vamos mejorando la forma de
presentar datos, así como también mi hablidad de
explicarlos y cosas.
2) Arrancar únicamente con 2 tópicos, así podemos
concentrarnos en replicar los resultados del paper de
Baumann.
3) Que en cada iteración el sistema recorrar a los N agentes
de manera ordenada, pero elija una pareja de manera aleatoria
(Esto va a resultar más complicado de lo que parece)

Por si acaso, antes de meterme con esto, resolver primero
el tema de registrar los datos y levantarlos con Python.

------------------------------------------------------------------

27/12/2020

En la carpeta de Aprendiendo C ayer armé un programa de Bash
para compilar archivos y correrlos. Eso lo importé acá,
se llama Compilar.sh. La idea es que para correrlo yo
uso en la línea de comando "./Compilar.sh Nombre_archivo".
El Nombre_archivo va sin .e, eso el programa de Compilar
lo agrega solo. Luego, el programa compila y te da la 
opción de elegir correr o no el .e. La idea es primero
revisar los errores. Si no salta ningún error, apretás
enter y se corre el programa. Si hay errores que corregir,
apretás una letra y después enter y no se corre el programa.

Hoy voy a encargarme de organizar el tema de que haya registros
de los datos. Lo que voy a hacer es armar archivos que guarden
la siguiente info:

.) Primera línea es la matriz de adyacencia.
.) Segunda línea es la matriz de Superposición
.) Tercera línea y en adelante es la matriz de Opiniones en cada
paso temporal.

Si tengo tiempo, me pondré a hacer lo que me propone Pablo sobre
variar la forma en que se elijen personas para realizar las
interacciones.

Se me está ocurriendo armar una función que reciba el puntero
al archivo y una matriz, y que copie toda la matriz. Como para
hacerlo más prolijo, por más que son sólo dos líneas.

Ok, ya logré usar los comandos para armar un archivo en donde
guardar los datos. Lo raro de esto es que por alguna razón no puedo
ponerle la extensión txt al archivo. No comprendo porqué. Igual eso
es lo de menos. Puedo fácilmente usar línea de comando o armar un
programa de Bash que se encargue de eso.

También me armé dos programas, uno para vectores doubles y otro
para vectores ints que me printea los datos. Teniendo esto, y
siendo que lo que me propuso Pablo es algo más trabajoso de hacer,
podría ponerme a trabajar en hacer un archivo de Bash que mueva 
mis archivos de mi carpeta actual a la de Programas Python.
Esto no está resultando tan fácil. Tampoco es tan importante,
lo dejaré para otro momento.

Más tarde, subiré las cosas a Github y armaré un registro de lo
que hice hoy. ¿Qué voy a hacer mañana?

.) Tengo que armar una carpeta en Drive y compartírsela a Pablo
y Sebastián.
.) Ahora que tengo un programa que guarda registro de mis datos,
voy a incorporar esto al main,
.) Cuando tenga al programa armando mis datos, voy a armar un
código de Bash que me los mueva todos a la carpeta de Datos
en la carpeta de Programas de Python.
.) Una vez que tenga los datos armados, voy a empezar a trabajar
en Python para ir viendo de levantar los datos y graficarlos.
.) Hecho todo esto, voy a empezar a trabajar en lo que dijo Pablo
sobre modificar la forma en que el sistema se itera.

--------------------------------------------------------------------------

28/12/2020

Ya agregué las partes de registro de datos al programa, funciona
bien. El tiempo que tarda me preocupa, voy a tener que trabajar
en armar las tablas previamente. Ahora voy a armar un archivo
que me mueva los datos.

Ya armé el programa que me mueve los archivos de datos a la carpeta
de Programas de Python. Despues quizás arme un archivo Bash que
lo levante, así de una al terminar de hacer todo me los mueva.
Posiblemente haga eso en el instanciar. Tipo, al final del for
muevo todo.

Antes de trabajar en Python, voy a anotar algo respecto a lo
que dijo Pablo sobre modificar la forma de iteración del
sistema. Entiendo que lo que Pablo dijo fue permitir que
todos los usuarios interactuen con todos, es decir una
matriz de adyacencia con ceros en la diagonal y unos afuera.
Se me ocurre que podría agregar un segundo agente en el struct
de la red. Luego debería supongo quitar a la matriz de adyacencia
de la ecuación y hacer que la cuenta se efectúe mirando a un
agente particular.
Ahora que lo pienso, el Din1 está calculando las tanh para TODOS
los agentes, incluso los no conectados. Eso es una pérdida de
tiempo abismal e innecesario. Podría meter un if en la función
Din1, pero creo que no sería lo óptimo. Lo mejor que se me
ocurre es armar un array de punteros a funciones. Que ese
array en la posición cero tenga una función que returnea un
cero, y en la posición 1 tenga a la función Din1. Ese array
lo creo en la función Din2, y eso sería mejor que tener un
if, porque no hay comparación involucrada. Y debería correr
más rápido el programa. Me gusta la idea. Ahora sí,
trabajemos en Python.

Ya logré armar un programa que levanta los datos de los archivos
y me genera un gráfico de la evolución de las opiniones. Lo que
grafica es el promedio del cuadrado de la opinión de cada uno 
de los agentes, y esto lo hace para todos los tópicos.
Este gráfico no sé si tendría mucho sentido para graficar
sistemas con K distinto de cero. Pero lo importante es que
el esqueleto está, modificar esto no sería tan difícil.

Lo interesante va a ser ver cómo graficar el caso de K distinto
de cero. Se me ocurre que puedo simplemente marcar con puntos o
líneas muy chicas las trayectorias en un plano 2D. Habrá que ver
cómo sale eso.

¿Con qué debería seguir? Ahora definitivamente es una buena idea
seguir con las propuestas de Pablo. Estos son los objetivos:

.) Modificar la iteración de manera de que cada agente se conecte
con otro agente aleatorio. (¿Cómo verifico que esto se cumpla bien?)
.) Modificar la función Din1 para que trabaje con un sujeto en vez
de con todos. (Asegurarse de guardar esta versión del programa
en algún lado, porque esta era la original. Esta era la buena.
Quizás simplemente lo deje comentado y listo.)
.) Corregir esa pila de cálculos innecesarios de las tanh que
después se mueren. Probar primero con un if. Y si eso no
es un gran progreso, probar la idea del puntero a dos funciones.
.) Armar las tablas de cálculo previo de las tanh y las funciones
de interpolación, para reducir el tiempo de cálculo de las tanh.
.) A futuro, cuando haya leído sobre el uso de archivos en el Tutorial
de C, ver de la posibilidad de armar una tabla una sola vez, y luego
cargarla, para deshacerme definitivamente de esa pérdida de tiempo.
.) Modificar el instanciar.sh para empezar a realizar muchas corridas
juntas. Agregarle al fondo el mover.sh. Eso es genial, me encanta.
.) Cuando esté consiguiendo cantidades ingentes de datos en la carpeta
de programas, ahí voy a tener que empezar a generalizar el funcionamiento
de mi programa de Python.

Mañana tengo que subir las nuevas versiones de programas de C y
de Python al Github.

----------------------------------------------------------------------------------

29/12/2020

Hoy lo que hice fue ver toda una sección de loops y decisiones en
el tutorial de C de AticleWorld. Aprendí un poco sobre los breaks
y el goto. Y sobre el continue.

-----------------------------------------------------------------------------------

30/12/2020

Ok, estoy pensando en hacer lo de la modificación al programa para que 
la iteración cumpla con la idea que propuso Pablo de agregar un elemento
random a la forma en que evoluciona el sistema. Se me ocurre que es
un buen momento para modificar el RK4 de manera de que se vuelva
incluso más general. Voy a sacar las iteraciones en agentes y tópicos
por fuera de la función.

Lo primero que debo hacer para hacer esto es guardar el programa que
tengo hasta ahora, para no perder nada de lo que ya funciona. Para
esto voy a empezar a usar la carpeta de Programas, ahí me voy a guardar
los archivos de esta versión del programa. Aunque voy a tener que usar
una carpeta, ya que esta versión que tengo del programa no va a funcionar
con la nueva versión del RK4, por lo que también va a necesitar su
correspondiente archivo general y demás.

Mañana arranco con las modificaciones. Si me pongo las pilas, ya mañana
tengo modificado el programa para que la iteración no sea ordenada.

------------------------------------------------------------------------------------

31/12/2020

Una idea para mis funciones es estandárizar el nombre que le doy a las
variables que registran el número de filas y columnas. A veces las llamo
i_C,i_CF, a veces i_columnas,i_filas, a veces i_Filas, i_Columnas. Tiene
que ser en lo posible siempre el mismo. Después voy a revisar todas mis
funciones y cambiarlo por el más sencillo, i_C e i_F.

Ahí probé la función RK4 modificada. Ahora efectivamente evoluciona a
una sola variable, y calcula todo correctamente. Ahora sólo queda
decidir detalles de si necesito o no armar un vector que me guarde
los datos extra para ir haciendo la comparación y poder decidir cuando
cortar el programa.

Igual lo siguiente a esto ahora es implementar esto en el main y ver
que efectivamente esto itera para cada sujeto. Seguramente armando 
una función Iteración que englobe al RK4.

Lo último que estaba haciendo es modificar la función Din1. El objetivo
es justamente modificar la selección del segundo agente de interacción
para volverla random. Estaba trabajando en eso armando una función
que toma un número y un rango de valores, crea un vector con todos
los números en el rango menos el que tomo como input. Luego genera
un número random menor al tamaño del vector, va a la casilla elegida
del vector y toma ese número. La función la estaba armando para el
caso de números ints.

Voy a tomar la siguiente regla de trabajo. Es cierto que soy muy
celoso con el tiempo de trabajo de mis funciones, pero voy a dejar
estos temas de optimización de código para más adelante. Por si acaso,
si pensás que te vas a ir olvidando de esto en el futuro, hagamos un
archivo llamado optimización donde guardemos las ideas de qué cosas
necesitan optimizarse, así cuando tengamos tiempo con el código y
no sepamos qué hacer, podemos invertir el tiempo en mejorar el código
y otro día resolvemos esos problemas grandes.

De paso, mañana cuando arranques con el programa de nuevo, acordate
de comentar la función esta de generar números aleatorios, sino te va 
a tirar altos errores.

-----------------------------------------------------------

01/01/2021

Modifiqué la función Din1 para que no tome al segundo agente como un
input, sino que el segundo agente sea un elemento dentro de los structs.
Luego armé al segundo agente dentro del struct de la red, que es i_agente2.

A la función Din2 le saqué el for que hacía que revisara todos los
agentes con los cuales el primer agente estaba conectado. Esto es para que
las interacciones sean únicamente de a pares.

Agregué en la iteración del main los elementos necesarios para definir
el segundo agente y para que el sistema itere en los tópicos y los agentes.

A la función RK4 le saqué todo el mambo de vectores k donde calculaba
el k para cada elemento del vector de opiniones y evolucionaba
todo el sistema junto, y lo reemplacé por un sólo vector el
cual contenía los valores de k0 hasta k4. El k0 es un extra
que agregué yo para generalizar el cálculo de los k y poder
hacerlos todos en un sólo loop, en vez de tener que escribir
4 acciones separadas para calcularlos.

Todavía no pasé esto al programa principal, todo esto fue en
el programa de pruebas.Así que todavía tengo eso por hacer.


Algo interesante que me llamó la atención. El sistema funcionando
de esta manera converge a un punto en el cual las opiniones
de los tópicos valen K o -K. El motivo de esto es que hay dos
términos en conflicto, el primero de -x y el segundo que tiene
K * tanh(...). El tema es el siguiente, como ahora no estoy
haciendo una sumatoria en todos los sujetos con los cuales mi
agente principal tiene conexiones, sino que hago interacciones
de a pares, mi segundo término es básicamente K*tanh(...).
Con un alfa suficientemente alto, la tanh cappea rápido,
por lo que se puede aproximar por 1. Esto me deja la
ecuación diferencial como -x+K*sgn(x). Esto es lo que lleva
a que el punto de equilibrio para todas las opiniones se
encuentre en el valor de K o -K. Antes esto no resultaba
tan evidente porque cada sujeto tenía una cantidad de
conexiones aleatoria, entonces me quedaba en el segundo
término K * sum(vecinos). Entonces cada agente tendía a
un valor que dependía de la cantidad de vecinos. 
De nuevo, como ahora las interacciones son de a pares,
todos tienen 1 solo vecino y por eso es que esto ahora
resulta tan evidente. Está copado poder observarlo.

Ya pasé todo al archivo principal, ahora funciona con este
sistema de interacción por pares. ¿Qué debería hacer mañana?

Los objetivos de cosas por hacer que charle con Pablo se 
pueden resumir en:

.) Optimizar más el código. Todo eso está anotado en el
archivo de Optimización.txt.
.) Modificar el archivo de instanciación de Bash para que
pueda ir tomando valores como input en la línea de comando
y que pueda correr muchas veces. Eso no es una gran
urgencia.
.) Mejorar el archivo de Python para que cuando esté con
grandes cantidades de datos poder levantarlas y graficarlas
mejor. Eso surgirá cuando esté graficando.

En principio, tengo una buena parte del trabajo ya hecho,
y eso que hoy es primero de Enero. Recordá que el gran
objetivo propuesto por Pablo es arrancar Febrero con los
dos gráficos de Baumann ya realizados. El de evolución
del sistema y el de los resultados según combinaciones 
de Delta y alfa.

Para cumplir esto también es importante revisar si Baumann
tiene algún código especial que use para hacer los gráficos.

Mañana voy a tomármelo libre. Lo que voy a hacer es armar
un archivo donde me anoto los objetivos Día a día.
Como para no tener que andar moviéndome para arriba cada vez
que necesito ir recordando qué hacer.

Algo que me estoy olvidando es de que debería armar un
mecanismo de corte automático del programa cuando el sistema
llega a un estado estable. Para esto, la idea es calcular como
un error cuadrático y ver la diferencia entre el vector antes
de iterar y después de iterar. Eso es lo siguiente a
implementar. Entonces mañana arranco con eso, y después lo
siguiente ya es empezar a trabajar en Python para armar
los gráficos. Ese debería ser el orden, creo yo. Bueno,
entonces el domingo arrancamos con ese mecanismo de corte.

Lo último que voy a hacer hoy es pasar todo el código del
archivo de pruebas al archivo Archivo.c, como para tener
guardada esta versión. Y debería subir todo a Github.

----------------------------------------------------------------

03/01/2021

Estuve intentando armar algo en el archivo Archivo.c de
manera de que me permita moverme rápido entre elementos.
No encontré un método útil. Después seguiré buscando,
y sino simplemente armaré una carpeta y pondré todo en
archivos separados.

Ahí corregí mis dos funciones, la de Norma y la de
Deltax, que ahora la llamo Delta_Vec_d.
Funcionan perfecto, Delta_Vec_d toma dos vectores
double, los resta y guarda la diferencia en la
tercer coordenada. Norma_d por su parte calcula
correctamente la norma del vector double que le
pases. Así que con esto estoy totalmente en condiciones
de hacer la modificación al programa del main para
que pueda registrar una condición de corte automático.
Igual, antes de armar la condición en el programa, me 
conviene primero calcular datos para un cálculo bien grande,
verificar cuanto tarda el sistema en llegar a un punto estable
y cuánto vale el error cuadrático en ese punto, como para tener
una noción de cuanto debe ser el error cuadrático. Además
ese error va a ser una función del tamaño de mi sistema, así
que estaría bueno ver si podemos hallar alguna relación
entre esas dos magnitudes.

Ahí coloqué esto en el main. Estoy teniendo un error de lo más
raro. Por alguna razón el programa no funciona, ya ni me itera
el vector de opiniones correctamente. No entiendo porqué
sólo está moviendo la primer coordenada, y además la mueve mal.
Es un total sin sentido esto.

---------------------------------------------------------------------

07/01/2021

Ahí empecé a retocar el archivo main que no funcionaba. Saqué los
elementos nuevos en los structs, saqué la función iteración del
main y todo rastro de los nuevos elementos del main. Con nuevos
elementos me refiero a los nuevos punteros y cosas que
puse en los struct que iba a necesitar.

El problema al parecer corría por el programa de iteración,
que lo reemplacé directamente por su código. Lo único que
realmente cambié es que en la iteración del for, en vez de
hacer un PRE incremento, lo pasé a un POST incremento.
Pareciera que esa fue la solución. Ojalá haya sido eso. 
Ahora voy a guardar el programa tal cual está, y voy a empezar
a agregar los elementos nuevos al struct. Espero que esta
vez no se rompa de nuevo.

Bien, ya incorporé todo y no explotó. No sé si funca,
pero por lo menos no explota. Quiero decir, llega al
resultado que llegaba antes, pero todavía no tengo
forma de saber que las funciones están haciendo su
trabajo correctamente. Por eso ahora lo que voy a hacer
es probar en Prosem si puedo abrir dos archivos en simultáneo
y escribir en ambos a la vez.

Ahí lo probé, funciona perfecto. De seguro el error estaba
en que quería usar el mismo puntero para dos archivos
distintos o algo así. Esto está buenísimo. Voy a además
empezar a usar esta notación de ahora en adelante, se siente
re natural.

Perfecto, el archivo ya funciona. Lo próximo que tengo que hacer
ahora es levantar los datos con Python, ver que está todo bien, y
empezar a hacer corridas masivas. Eso no suena muy bien. Me refiero
a correr el programa muchas veces, para muchos valores de N distintos.

Mi objetivo es ver si existe alguna variación de los valores de 
error cuadrático al ir variando el tamaño de la red. Considerando
que al ir aumentando el número de sujetos aumenta también el
número de coordenadas que tienen que restarse y luego sumar
su error cuadrático, yo pensaría que tiene que aumentar. Pero
también es cierto que el error cuadrático que estoy calculando
está normalizado según el número de agentes y tópicos, por tanto
NO debería cambiar con el cambio de número de agentes y tópicos.
Esto es muy importante para poder definir un criterio de corte del
sistema.

¿Que es lo próximo que tengo que hacer entonces?:

.) Levantar los datos en Python y ver que las funciones estén
trabajando correctamente.
.) Modificar el main para que tome datos desde la línea de comando.
.) Modificar el Bash para que las instanciaciones corran el programa
y luego manden todos los datos a la carpeta de C correspondiente.
.) Si queda tiempo y ganas, investigar un poco sobre cómo cambiar el
nombre de mis archivos para agregarles una extensión txt.

Voy a subir todo esto a GitHub

----------------------------------------------------------------------------------

08/01/2021

Ahí subí todo a Github hoy a la mañana. Por accidente apreté enter
y subí los archivos del Source sin un nombre correcto, ni hablar de
que no le puse descripción. En ese archivo se puede ver que ya cambié
todos los i_filas (y las columnas también), y les puse un único nombre
en todas las funciones, para que sea siempre i_F e i_C.
Eso era una tarea de unificación necesaria.

Ahora voy a empezar a trabajar en Python para armar una estructura que
levante los datos y los grafique. Mi objetivo ahora es mirar un poco
cuando se produce el corte en mis datos y ver si puedo armar alguna relación
entre la variable de corte, K y N.

El programa de Python me parece que está bastante prolijo y ahora está
armado para levantar los datos de los archivos y graficarlos. En particular
lo que hace la función es tomar las opiniones de todos los sujetos en
una iteración respecto a un tópico, elevarlas al cuadrado, sumarlas y
normalizarlas según la cantidad de agentes.
Además, por una cuestión de que la leyenda del gráfico no me tape todo,
antes de graficar los datos lo que hago es sumar estos valores al cuadrado
y sumados de todas las opiniones de un tópico sobre todos los tópicos.
De esa manera lo que estoy graficando es una sumatoria de las opiniones
sobre TODOS los tópicos. Repito que esto es para una simplificación de la
graficación por un tema de que al final del día yo espero que todas las
opiniones se estabilicen en algún valor, por lo que como todas convergen
a algo, la suma también va a converger. En este momento perder rastro de
los valores de cada opinión no es un problema porque lo que yo quiero medir
es más o menos cuantos pasos requiere el sistema para alcanzar un punto
de convergencia. Al parecer con 7500 paso le sobra a todos los sistemas.

Es más, cuando lo corra en C para tener bastantes más datos, lo que
podría hacer es reducir el tiempo de corrida a 10000 paso.

Bueno, ¿qué voy a hacer la próxima vez que agarre esto?:

.) Tengo que terminar de armar el cargado de datos de los errores cuadráticos.
Necesito eso para determinar correctamente un punto de corte.
.) Modificar el main para que tome datos desde la línea de comando.
.) Modificar el Bash para que las instanciaciones corran el programa
y luego manden todos los datos a la carpeta de C correspondiente.
.) Si queda tiempo y ganas, investigar un poco sobre cómo cambiar el
nombre de mis archivos para agregarles una extensión txt.

-------------------------------------------------------------------------------

09/01/2021

Ya armé el programa para que tome los archivos de errores y lo grafique.
Fue bastante fácil, total fue hacer una copia casi del código
para graficar los datos de opiniones. Lo raro es lo que estoy viendo en
los datos. Al parecer el sistema primero cae a un primer mínimo local.
Esto se encuentra cerca de las 2500 iteraciones. Hasta este punto, la
evolución parece bastante caótica porque la suma de diferencias cuadráticas
oscila fuertemente. Luego de eso el ruido se reduce de forma considerable
y las diferencias cuadradas comienzan a aumentar hasta llegar a un pico
claramente definido, apenas antes de las 5000 iteraciones. De ahí descienden
las diferencias a cero de manera progresiva y sin ningún ruido.
Es como si el sistema alcanzara un punto crítico en el cual se
decide un claro estado "ganador" que se encarga de absorber a todos los
demás estados. Me lo imagino como que se habían formado ciertas comunidades,
(Cosa rara porque no hay ningún mecanismo de formación de comunidades),
y luego el gran cambio se da porque una comunidad colapsa y es absorbida
por la otra.
Lo interesante es que jamás se me hubiera ocurrido ver esto tomando en cuenta
los gráficos de opiniones. Ese gráfico, con las pérdidas de información
que implica, pareciera sugerir un progresivo avance hacia una dirección
que ya en la iteración 5000 pareciera haberse prácticamente establecido.

Esto es raro, pero bueno, ahora voy a tomar MUCHAS mediciones más
y ver qué pasa. Mi mayor miedo es qué hacer con la leyenda. 
Quizás la ignore. Eso lo pensaré una vez que tenga mis datos.

Primero tengo entonces que modificar el archivo Bash.
También tengo que armar una carpeta separada para guardar mis nuevos
datos. No quiero borrar los que tengo hasta haberlo charlado con
Pablo.

De paso, te comento que por alguna razón no habías realmente
normalizado los errores. Sólo para que lo sepas. Igual quizás
también convenga multiplicarlo por algún número grande,
sólo para que no se vea tan chico.

Armé un nuevo archivo en Prosem para probar un poco el tema de
mandarle números al programa a través de input por línea de comando.
En el mismo archivo está explicado detalladamente cómo funcionan las
variables argc y argv, así como la función strtol que voy a usar para
el programa. Ya mañana lo puedo mandar a correr y sacar muchos
datos.

Lo que sí voy a necesitar es armar una segunda carpeta donde
guardar esos datos. Y modificar el instanciar.sh para que
mande todos los archivos a esa carpeta y no a la ya existente.

----------------------------------------------------------------------------------

10/01/2021

Cosas importantes de hoy. Ya modifiqué el instanciar para que
corra muchos N y muchos K. Es más, ya lo hice correr, así que
eso ya está hecho. Además el programa levanta todos los archivos
con nombre "Datos_*" y los mueve a la carpeta de Datos Corte
dentro de la carpeta de programas Python.

Por otra parte, al parecer el antivirus era lo que impedía
que el comando mv cambie los nombres de los archivos. Así que
modifiqué eso ahora para que los nombres de los archivos movidos
se escriban como txt.
Ahora que lo pienso, si bien puedo hacerlo, eso no necesariamente
es bueno. Creo que voy a seguir trabajando sin eso, porque al final
me va a generar más problemas.

También tuve que poner una nueva función, strtof, que me permite
convertir números en floats. Bah, yo digo que tuve, pero en
realidad lo hice por si acaso porque el número K está definido
como un float, pero en realidad no sé si me hubiera tirado un
error el usar el strtol.

Ahora debería levantar los datos con Python y ver qué me da. 
Eso lo haré mañana seguro.

--------------------------------------------------------------------------------

14/01/2021

Estoy anotando esto con un día de retraso.

Lo que voy a hacer hoy es tomar los archivos de Python y
modificarlos de manera de que me hagan un gráfico de Opiniones
y uno de Errores por cada valor de agentes N, y que en cada
gráfico entren todos los valores de K considerado. La idea es
separar un poco todas las curvas para poder entender mejor qué
está pasando.

Bien, ya logré hacer esto. De paso intenté generalizar el sistema
haciendo que primero reconozca los valores entre los cuales se
mueve N y de ahí el código grafica todo correctamente.
Ahora sería interesante lograr que me guarde los gráficos automáticamente,
así puedo mirarlos mejor y más cómodo en la pc en vez de mirarlos
en el notebook de Python.

Bueno, eso fue sencillo, lo realicé con la función plt.savefig().
Listo, ahora voy a subir estos datos al powerpoint de la tesis,
voy a subir todas las imágenes asociadas a una carpeta
que se llame: "Datos Corte", porque son los datos que
voy a usar para definir el mecanismo de corte.

Ya está todo subido y correctamente documentado en el archivo
de powerpoint de la tesis.

¿Qué es lo que sigue?

1) Debería empezar a pensar un criterio de corte y ponerlo
a prueba con los datos. La idea sería que el sistema me grafique
una línea vertical en mis plots y con eso poder comprobar cuándo
el sistema cortaría las iteraciones según ese criterio.
2) Para lo anterior estaría bueno comprobar si realmente
los valores de ErrCuad están debidamente normalizados o si
varían con los valores de N y K. Lo ideal sería que estén
correctamente normalizados. Eso me garantizaría que puedo
tomar algún valor arbitrario como criterio definitivo
y estar tranquilo de que nunca va a pasar que el sistema
nunca llegue a cumplirlo.
3) Hacer el gráfico de las opiniones para el caso de N=5 
que tiene ese error con el pico raro. Así lo podemos analizar
más en detalle.
4) ¿Podría normalizar los errores cuadráticos usando 
el máximo del error o no? El problema de eso es que
eso tiene sentido una vez que YA tenés los datos de errores
calculados, no me ayudaría a armar un criterio de
corte para el sistema mientras corre

-----------------------------------------------------------------------------------

15/01/2021

Lo primero que hice fue revisar que no faltara nada en el Github.
Luego cloné el repositorio de Github en mi carpeta de SiCoMoDa. La
idea es empezar a usar Github Desktop como una forma más sencilla,
(y parece que sinceramente lo es), de ir comitteando el progreso
de mis archivos. De esta manera no soy yo el que tiene que estar
atento a qué cosas se modificaron, sino que el programa me avisa de
qué se modificó, crea las carpetas necesarias, sube los archivos.
Es realmente más cómodo.

Estuve dándole vueltas al asunto del criterio de corte, todavía no
llegué a un criterio razonable. No me convence del todo la idea de 
pedirle al sistema que corte cuando llega a cero. ¿Porque si nunca
llega a cero que hacemos? ¿Y si cero es una aproximación?

Estoy pensando en una cota variable, que sea una fracción del máximo
de error. De esa manera puedo desentenderme del tamaño de mi sistema
y del valor de la influencia K. En este caso se me ocurre darle un 
período largo, unas 1000 iteraciones, en las cuales el sistema se
encuentre en un intervalo del 10% o del 5% del valor máximo.
La idea sería ver en los valores que tengo cuánto "tiempo" el
sistema se encuentra en ese intervalo. Si el tiempo que se encuentra
ahí es muy grande, es decir que ya en el principio cumple ese criterio,
el criterio es super holgado y no me sirve. Necesito ver que el sistema
comience a cumplir con el criterio que yo establezca en el último tramo
de su evolución.

Por otro lado, para ver si existe una correlación entre K y N y la
cantidad de pasos necesarios para que el sistema deje de evolucionar
es que armé un gráfico que me marca la cantidad de ceros que hay en
el vector de Errores. El motivo de mirar la cantidad de ceros es que en
todos los sistemas una vez que el sistema llega al cero, no vuelve
a levantar cabeza. Entonces el número de cantidad de ceros es de alguna
manera la cantidad de iteraciones demás que hizo el sistema. Si el
sistema tardara más en llegar a un equilibrio para valores de N y K
grandes, entonces yo debería ver una caída en la cantidad de ceros
a medida que K y N crecen.

Creo que estaría bueno hacer cuentas para algunos valores de N más.
Voy a hacer eso y ver si se ve algo claro.

Ok, hice unas cuantas sumas más para valores de N entre 16 y 30. Por lo
que vi no aportan MUCHA más claridad. Pareciera que efectivamente
valores bajos de K llegan a una convergencia total más rápido a medida
que N aumenta. Después "pareciera" que los valores de K más grande
tardan más en llegar a una convergencia, y los valores intermedio
"pareciera" que se organizan de manera que la cantidad de pasos
necesarios para converger totalmente disminuye a medida que disminuye
el K. Pongo comillas al pareciera porque la verdad tampoco es
algo definitivo. El K=1 oscila terriblemente, el K=3 a veces
está por debajo del K=5, a veces por encima del K=1. No es claro.

Después armé un código para marcar sobre los gráficos de Errores_Corte
unas barreras de porcentaje respecto del valor del error máximo.
La idea es visualizar cuántas iteraciones el sistema tarda en reducir
sus errores por debajo del valor máximo, siendo que la mayoría de los
comportamientos de los errores son monótonamente decrecientes y que
por tanto los máximos suelen encontrarse al principio del gráfico.
También sirve para ver cuánto vive el sistema en cierto umbral, de manera
de determinar si el hecho que el sistema atraviese esa barrera es un 
buen criterio de corte o si resulta muy holgado, o muy estricto.

Para la próxima la idea entonces es 
.) Guardar los gráficosde Umbrales_Error. Van a ser MUCHOS gráficos, 
la idea es mirar un poco a ojo que efectivamente una vez que el 
sistema cruza la barrera del 0.5%, por decir un número, se encuentra
a unas 1000 o 2000 iteraciones de terminar. Entonces le podemos
pedir que corte luego de 500 iteraciones una vez cruzado ese
umbral.

.) Para cerciorarme cuántas iteraciones hay de distancia desde que
el sistema cruza la barrera que le digo que cruce, podría hacer alguna
clase de resta entre el índice en el cual cruza la barrera
y el valor en el cual los errores se vuelven cero. Creo que este
gráfico va a ser el definitivo para elegir un criterio. Idealmente,
todos los sistemas tienen un mismo valor de cantidad de iteraciones
desde que cruzan la barrera y eso me permite asegurarme que nunca
corto muy temprano o muy tarde. Realísticamente van a ser números
con algo de suerte no muy dispares. De ahí, si quiero un criterio 
más holgado, puedo tirarme a elegir uno de los números altos,
si quiero un criterio estricto puedo tomar valores de los bajos,
si hay mucha disparidad puedo tomar un promedio, ya veré cuando
tenga el gráfico.

De paso, la idea es que ese gráfico me va a dar una idea
de cuánto tarda el sistema luego de cruzar una cierta barrera
en llegar a una convergencia TOTAL, donde ya no varía más.
Por eso si tomo alguno de los valores más grandes el criterio es
holgado, porque en ese caso lo que va a pasar es que los sistemas
van a por si acaso pasar tiempo sin evolucionar en favor de que
ningún sistema se quede sin llegar a ese estado.

-------------------------------------------------------------------------------------

17/01/2021

Por alguna razón, recién hoy se me ocurrió pensar que quizás, sólo quizás,
estaba guardando mal mis datos. Efectivamente se me estaban guardando los datos
con una precisión de seis decimales. Lo cual es una gran cagada consideranco que
estoy trabajando con doubles, es decir que el programa tiene datos con precisión
de 12 decimales. (Leí que técnicamente son 14, igual yo por si acaso le pido
sólo 12).

Así que lo que hice fue primero probar en un archivo aparte cómo lograr que se
printearan datos con precisión de más de 6 decimales, logré que se printeara
con 12.

Luego, pasé eso al main y me aseguré que los errores y los valores de opinión
tuvieran esa precisión. Aunque siendo sincero, los valores de opinión no necesitan
semejante precisión. Digo, esos números rondan los enteros, ¿Para qué carajos
quiero 12 decimales más de precisión? Pero como digo, ya están calculados,
no es que me esté ahorrando cómputo no anotándolos.

Lo otro que hice, que me siento muy bien por haberle encontrado la vuelta,
es darle un sentido a la variable de Error_Cuad. Hasta ahora era sólo un
número que en la medida que se iba a cero me marcaba que el sistema cambiaba
cada vez menos, pero ni idea de qué representaba. Lo que hice ahora es normalizarlo
usando la definición de norma para que ese número represente la VARIACIÓN PROMEDIO
DE CADA OPINIÓN. De esta manera, si ese número es 0.0001, lo que me dice es que
en promedio TODAS las opiniones variaron eso. Eso es lo que significa ese número
ahora. Por eso decidí llamarlo ahora en el código VarProm, es decir Variación Promedio.

Me doy cuenta que el nombre de los archivos sigue siendo Datos_ErrCuad_... .
Debería cambiarlo para llamarlo variación promedio y reflejar mejor el sentido
de ese valor. Dejaré eso para otro día. Lo bueno es que puedo cambiar eso
sin necesidad de cambiar el código de Python en nada.

Esto hace que mi análisis de la cantidad de pasos que el sistema necesita
para llegar a una convergencia TOTAL sea una total pelotudez. Debí darme
cuenta de la terrible gilada que estaba diciendo.

Ahora, visto y considerado esto, habría que considerar que el criterio sea
un número fijo ahora que la variable representa algo claro del sistema.
Por ejemplo, si propongo que el criterio sea 10^(-6), sería decir
que si las opiniones empiezan a variar en valores menores a la
millonésima parte, entonces considero que el sistema deja de
evolucionar y llegó al estado de equilibrio. Suena bastante
razonable, recordando que mi sistema se mueve en el orden de los
enteros. Es decir, las opiniones en promedio estarían variando 
en 6 órdenes de magnitud menos que sus valores actuales. Por tanto
esa es una variación desreciable. Si el sistema entra en esta región
y no escapa luego de un tiempo, lo podemos cortar y listo.

En lo que queda del día me voy a poner simplemente a ordenar todo,
subir todos los datos correspondientes y listo. Estoy actualizando
programas y archivos de Documentación.

Cosas pasaron y tuve que borrar los archivos de datos que tenía
en la carpeta local, por lo que aproveché para mandar a correr de
nuevo todo el programa. Así que no voy a tener tiempo de subir
las imágenes a la carpeta de Tesis, eso queda para otro día.

¿Qué es lo próximo para hacer?

.) Implementar el sistema de corte en el main. El criterio
seguro sea que la variación atraviese el piso de los
10^(-6) durante unas 500 iteraciones.
.) Mirar en el trabajo de Baumann cómo realizó las imágenes.
Empezar a intentar hacer esas imágenes.
.) Subir las imágenes que tengo al Drive para mantener
registro de todo. (Quizás arranque por esto)
.) Optimizar el código en el tema de la tanh. A esta altura
los tiempos de corrida están empezando a ser molestos, me gustaría
reducirlos.

------------------------------------------------------------------------------

19/01/2021

Ayer subí los gráficos al Drive. Al final borré algunos que tenía de
antes porque ya no eran válidos. Y subí uno de los nuevos de Variación
Promedio de las Opiniones.

Hoy ya armé una función que implementa el criterio de corte. Algo gracioso
es que al armar esta función pude claramente observar la diferencia entre
pasar una variable por copia o por referencia. Al principio estaba pasando
el parámetro de corte por copia. Eso hacía que mi sistema nunca cortase
porque el parámetro de corte nunca variaba, sino que lo que variaba era su copia.

La solución entonces fue pasar el parámetro por referencia, y se solucionó
bárbaro. Creo que ese problema no lo voy a tener en mi sistema, pero bueno,
esto muestra lo importante que es seguir con el tutorial de C. Quiero llegar
a la parte donde habla sobre structs.

Al final decidí pasar el código y no armar una función en el main. El motivo
de esto es que siento que sino estoy pasando MUCHAS veces el struct por copia.
Eso me preocupa un poco. También está el tema de que iba a tener que definir
muchos argumentos para la función, por el hecho de que iba a tener que
pasar los punteros a mis archivos en los cuales estoy anotando los datos.
Para ahorrarme eso, decidí simplemente copiar el código fuente en vez
de pasarlo en una función. En un futuro, cuando decida corregir el pase
por copia a un pase por referencia, quizás convierta todo esto a una función.
O cuando me arme la función que interpola las LUT.

Ahí lo implementé y estuve mirando los números. Tomando un criterio de corte
de 10^(-6), lo que observé es que en las últimas iteraciones el sistema
está variando en la séptima cifra decimal en valores promedio de tres o cuatro.
Es decir, ~4*10^(-7). Por tanto, el programa está cortando correctamente.

Ya subí el programa con las nuevas implementaciones a Github.

--------------------------------------------------------------------------------

21/01/2021

Ahora que el mecanismo de corte funciona, lo que voy a hacer
es crear una nueva muestra de datos y graficarlos en Python, para
ver que el código funcionó bien.

Ahí miré las imágenes, parece estar bárbaro. Cada iteración corta
luego de 1000 iteraciones de haber atravesado el piso de 10^(-6).
Y en los gráficos de las opiniones se ve que cada uno corta
a ritmos diferentes, pero siempre la curva se ve como que
deja de variar.

Ahora lo que voy a ver es si Baumann tiene algo anotado
sobre el código con el cual arma sus gráficos. Sino, tuve algunas
ideas de cómo reproducir esos gráficos por mi cuenta.
Bueno, en lo que yo leí no vi ninguna referencia a un código
o software especial usado para generar esos gráficos.
Queda entonces arremangarse y hacerlo yo mismo. Por ahora
dejemos de lado las distribuciones, arranquemos con los gráficos
que muestran como la opinión de los agentes se van
moviendo. La idea es que las opiniones armen una trayectoria
en línea gris. Es decir, voy a tener que armar vectores con 
la opinión de un agente en cada iteración, graficar eso con una
línea muy fina y gris. Luego, en el punto final, le pongo
un punto grande con un color que tenga que ver con el ángulo
que forma el vector, tomando en cuenta una distribución de todos
los colores según el ángulo que forman con la horizontal.

Para el tema de estudiar cómo varía el estado final del sistema
con delta y alfa, lo que voy a hacer es dentro del mismo programa
de C, o quizás en Python, un código que discrimine los distintos casos
en función de los signos de las opiniones finales y de sus módulos y
le ponga la etiqueta de: Consenso, Polarización y Estado Ideológico.
Luego, en Python tomo la etiqueta y a ese punto le coloco un marcador
cuadrado del tamaño correcto y con el color asociado a la etiqueta.

Ya modifiqué un poco el archivo del main para que me empiece a 
generar los datos que voy a necesitar graficar. En este caso
cambié los nomrbes de los archivos, me deshice del archivo de
Variación promedio de las Opiniones porque creo que no lo voy a necesitar
y ya modifiqué el Mover.sh. Ahora me voy a poner en Python a armar
el gráfico de estos datos.

De paso, también voy a armar una documentación en la carpeta con
imágenes de los archivos creados con el mecanismo de corte implementado.

-------------------------------------------------------------------------

27 y 28/01/2021

Esto es una entrada doble porque ayer arranqué con esto.

Mi idea es empezar a probar el tema de optimizar el código. Busco
implementar el uso de un archivo en el cual se encuentren ya calculados
los valores de la tanh. De esa manera mi intención es reducir el 
tiempo de cómputo de cada iteración y así poder correr los datos más rápido.
Porque con el tiempo actual esto resulta muy poco viable. Supongo que
podría ganar tiempo reduciendo alguna cantidad de cuentas, pero entiendo
yo que si quiero armar un gráfico similar al que hace Baumann para
determinar en el espacio de sus variables cuando el sistema llega 
a un consenso o cuando se polariza, voy a necesitar hacer un
barrido fino. Por no decir que técnicamente tendría que iterar
muchas veces y tomar un promedio, no alcanza con una sola iteración.

Reducir el tiempo de cómputo es PRIORITARIO.

Por eso partí de armar un archivo "Tabla_Valores_Prueba". En este
archivo armé una matriz de 3x3 con números en sucesión.
Probé el uso de la función fgets. Si bien está copada porque
lee una cierta cantidad de caracteres, los convierte a string
y los mete en un puntero, mi problema es que hasta donde
entiendo sólo puede levantar chars. Eso es un problema, porque
entonces no podría correctamente levantar los números doubles.

Ahora estoy pasando al uso del fscanf. Por lo que entiendo,
fscanf busca el patrón que le armás en el centro y eso se lo
pasa a las variables que le indicas. Entonces ignora totalmente
los newline y por lo que vi, ignora las tabulaciones también, porque
le estuve pidiendo que levante ints, que son los números que como
dije antes puse en la matriz, y ni registro tuvo de las tabulaciones.
Entonces se me ocurre que puedo armar un vector, o dos valores ya veré,
en los cuales guardar los números que necesito para la interpolación.

Mi idea hoy seria investigar un poco el fseek(). La idea sería poder
leer el archivo sin tener que pasar todos los datos a un puntero.
Lo cual sería una re cagada y creo yo que haría que todo este trabajo
sea reverendamente al pedo, porque el archivo va a tener muchos datos
ya de por sí. Eso es algo que también tengo que ver, si abrir un archivo
pesado requiere mucho trabajo o no.

Pero volviendo al fseek(), eso me permitiría fácilmente moverme en el
archivo. Esto además es muy importante porque el instanciar va a hacer
que el programa se cargue muchas veces, haciendo que el archivo se abra
y cierre muchas veces. Entonces, nuevamente, estaría perdiendo un
montón si tengo que cada vez cargar todo el archivo. De nuevo,
reverendamente al pedo.

Ok, el fseek() parece bastante sencillo. Además, comprobé que las 
tabulaciones ocupan una posición cada una, efectivamente. Ahora
debería comprobar que efectivamente los double ocupan un único
espacio, cosa razonable, y algo más importante, que el fscanf
avanza el indicador de posición a la posición inmediatamente
siguiente en la cual termina el patrón que busca, una vez
encontrado. Esto es importante porque si quiero moverme leyendo
desde el archivo, necesito total control de la posición del indicador.

Para esto voy a necesitar entonces las funciones ftell() y rewind().
ftell() me devuelve un int que me indica la posición del indicador,
mientras que rewind() regresa el indicador a su posición inicial. 
No sé si ese sea tan necesario o útil.

Bien, como yo supuse, el fscanf revisa el archivo hasta encontrar
la primera instancia del patrón indicado. Luego lee el patrón,
envía los elementos a las variables indicadas y luego avanza
una posición más. Cabría ver que los doubles ocupan exactamente
el mismo lugar, pero eso es casi obvio. Igual lo voy a probar.
Una vez hecho eso, lo que voy a hacer es archivar esto, armar
un archivo gigante y ver si el revisar algunos de sus elementos
me consume mucho tiempo.

Menos mal que probé si los doubles ocupaban el mismo lugar. No lo
hacen. Cada número guardado de un double tiene una posición propia.
Lo que ocurre es que el scanf sabe interpretar el número y lo lee
entero cuando le decís que tiene que levantar un %lf. La pregunta
interesante es, ¿Lo levantaría igual si el número tuviera más decimales?
¿O en ese caso habría que indicarle la cantidad de decimales? Además,
¿Qué pasa si arranca a leer número por la mitad?

.) Ya probé lo de indicar más decimales, eso no funcionó. La función
fscanf() no permite agregar el número de decimales como parámetro
a la hora de levantar datos, entiendo yo que lo que pasa es que lo levanta
todo y listo.

.) Sobre arrancar el número por la mitad, lo que hace es tomar el número
desde el cual arranca y lo lee todo hasta encontrar un punto o un final.
Vas a tener un problema en las cuentas, pero nada malo va a pasar en términos
de crasheos.

.) Si el número de decimales es mayor, el tipo lo lee correctamente. Recordá
que lo que hace fscanf al leer un "%lf" es mirar el número, ubicar el punto
y leer hasta que haya un corte del número. Entonces si el número tiene más
decimales no importa, lo va a leer hasta que se corte. Por tanto, lo que
marca el final del número es la tabulación al final del día.

Bueno, habiendo hecho todas estas pruebas estoy en condiciones de armar
una función que lea los datos que yo quiero leer. La idea de
la función es que reciba el puntero al archivo, usando fseek() ubique
los valores a interpolar y luego pase esos valores a una función de
interpolación. O que ella misma interpole. Igual quizás la interpolación
la arme aparte sólo para tenerla para futuras funciones.

Entonces, ¿Cuáles son los objetivos mañana?

.) Primero, mandar a correr el programa para crear un archivo con millones
de datos. Estaría bueno primero probar de armar un archivo de muchos datos
y ver si el programa le toma tiempo abrirlo, buscar dos números y volver.

.) Definir los intervalos en los cuales voy a calcular mi tanh. La idea
es cortar en algún punto donde pueda aproximar la tanh por 1. También
definir cada cuanto debería hacer el paso de la tanh. Para eso estaría
bueno ver una medida de cuánto varía la tanh punto a punto, porque
quizás varía cada 10^(-6) y el tipo varía en 10^(-3) cada 10^(-4).
Entonces tendría una precisión de 100 valores en los cuales yo no noto
diferencia de la función.

.) Armar una función de Interpolación de los datos.

.) Archivar la función de prueba armada hasta ahora. Ordenalo para
que se vea un poco más fácil de entender la próxima vez que quieras
mirarlo. Separa la parte escritura de la parte de lectura.

------------------------------------------------------------------------------

29/01/2021

Ya guardé los datos en el programa de Archivo.c. Ahora lo que voy a hacer
es armar la tabla de datos. Ya hice un primer archivo en el cual guardé
1 millón de datos double. Eso me tomó siete segundos. Por tanto podría guardar
10 o 100 veces esta cantidad de información y no sería mucho problema.
Sería una tarde trabajando, ningún problema. Creo, veamos si ahora
intento guardar doubles, pero que sean tanh.

Es algo totalmente inesperado, pero el programa tardó 4 segundos menos
en guardar valores de tanh. No entiendo qué pasó ahí. Pero bueno,
cosas pasan. Hagamos unas pruebas sobre tiempo de cómputo primero.

Esto no pareciera que es un problema. Estoy probando el uso de la función
tanh para realizar diez millones de cuentas y lo estoy comparando con la
realización de unas simples cuentas de multiplicación y suma. Las mismas
cuentas que más o menos haría con la función de interpolación.
No logro ver una diferencia  de tiempo en el cálculo que hace el programa. 
Digo, los dos parecen tardar cero segundos. No parece haber ninguna
diferencia, como que la tanh no le aporta mayores problemas al cálculo. 
De ser así, no tiene ningún sentido que haga todo este quilombo para cambiarla
en mi función original. Quizás vale más la pena que revise el
funcionamiento general del modelo y empiece a trabajar en el 
armado del gráfico de los estados finales del sistema en función
de las opiniones alcanzadas.

Ahí está, ahora sí pude poner a prueba esto. Casi se me cae el
mundo a pedazos. Como mi medición del tiempo no tenía una precisión
que me permitiera diferenciar cuál proceso tardaba más, lo que hice
fue meter a los dos loops en un while y ver cuál proceso lograba
en un segundo realizar más ciclos. El resultado fue que el proceso
que agregaba una tanh realizaba un 40% menos de ciclos en el mismo
intervalo de tiempo. Por tanto, hay una diferencia apreciable
y vale la pena optimizar al sistema con la implementación de un método
de interpolación de los valores de mi tanh().

Ok, momento, todavía no está todo dicho. Esto parece tener una variabilidad
de la concha de la lora. Volví a mirar al sujeto que hace las cuentas
simples, el que le ganó por un 40% en los ciclos, y en una iteración
apenas logró realizar 9 ciclos. En otra realizó 76. Creo
que voy a tener que guardar muchos valores y luego armar un histograma
y compararlos. Qué paja.

---------------------------------------------------------------------------

31/01/2021

Bueno, estuve retocando el Instanciar.sh para que mañana simplemente lo
mando a correr y eso pueda estar tranquilamente tres putas horas corriendo.
Todo para armar un cuarto de los archivos que necesito y encima con sólo
500 agentes, no con 1000. Pero bueno, es lo que hay, quiero gráficos.

Por otro lado, también armé un programa para medir los tiempos de cómputo
y comprobar que efectivamente vale la pena implementar una función de
interpolación. Con eso me guardé los datos y armé un histograma. El histograma
está guardado en la carpeta de Tesis. La idea es simplemente que hice
que el programa realice muchos cálculos, unos simples, unos con tanh.
La idea es que para medir cuál caso trabaja más rápido los hice
hacer una tarea similar y ver quién puede hacerlo más veces seguidas.
Guardé esa cantidad de veces y eso es lo que grafiqué en el histograma.

Ya archivé los datos, pero no subí nada a Github.

¿Entonces, qué debería hacer mañana?

1) Armar muchos archivos y empezar a armar los gráficos
correspondientes en Python. Va a haber muuuucho cálculo de fondo.
2) Definir los intervalos para calcular la tanh. Para esto calcular
la derivada de la función y ver cada cuanto varía. Creo que puedo
incluso hacer un barrido cada 10^(-5).
3) Armar efectivamente la función de interpolación.

------------------------------------------------------------------------

06/02/2021

Estos días estuve estudiando E4 fuerte, por eso casi ni me puse con esto.
Hoy ya me encargué de poner en todos los gráficos subidos al powerpoint
de la tesis las ecuaciones que indican los valores graficados.

Mañana debería preparar se gráfico explicativo de la forma en que se
resuelve cada iteración. También estaría bueno ver lo que me preguntó
Pablo sobre si el sistema sigue reduciendo el valor promedio de 
variación de opiniones de manera indefinida. Ya comprobé que un double
te puede guardar hasta 30 decimales sin problemas. Re flashero.

También tendría pronto que empezar a trabajar en el tema de la función de
interpolación y el armado de la tabla de valores de tanh calculadas.

------------------------------------------------------------------------

07/02/2021

Hoy terminé de subir unas imágenes de los gráficos de trayectorias de
opiniones que ayer no había subido. Ahroa sí, no me queda nada por
subir al archivo de power Point. Debería empezar a trabajar en el
armado de los gráficos para explicarle a Pablo las interacciones entre
agentes. Y en el armado del archivo que guarde datos para ver que el sistema
no cae hasta el infinito.

------------------------------------------------------------------------

09/02/2021

Armé un archivo con las opiniones y otro con la variación promedio para un
número de 200 agentes, un K=5, T=2  y lo hice correr un total de 60000 pasos.
El objetivo es ver si el error cae infinitamente o en algún momento se plancha.

Ahí armé el gráfico de esto, y de paso corregí el código de Python para que
cuando arme estos gráficos, si hay un salto en el número de agentes no
guarde gráficos vacíos. Eso me pasaba porque antes me meovía entre valores
mínimos y máximos de N, por lo que no sabía que había en el medio.
Ahora lo corregí para que me arme un conjunto con todos los valores
de N para los cuales existe un archivo de datos, así sólo grafica
para valores de N existentes. Es decir, para archivos que tienen
ese valor de N.
	De paso, no corregí esto para la sección del código que arma
los gráficos sacados de la carpeta de interacción de Pares. Así que
atento a eso.

Cuestión, por lo que vi del gráfico hecho, el error no cae infinitamente.
Pareciera que llega como hasta 4*10^(-17) y después cae directamente
a cero. Y eso teniendo en cuenta que guardé hasta 20 decimales. Así
que pareciera que no cae infinitamente, lo cual es genial

------------------------------------------------------------------------

10/02/2021

Subí los gráficos que hice para el caso de 200 agentes con el objetivo
de ver si el error del sistema eventualmente caía a cero. También
lo puse en el archivo de Powerpoint. Los gráficos están en la 
carpeta de Corte, para que no quede ninguna duda de dónde están.